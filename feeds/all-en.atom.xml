<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Stacking Roshan Blog</title><link href="https://RoshanStacker.github.io/" rel="alternate"></link><link href="https://RoshanStacker.github.io/feeds/all-en.atom.xml" rel="self"></link><id>https://RoshanStacker.github.io/</id><updated>2021-10-16T05:56:00+11:00</updated><subtitle>Hacker and Automation Engineer!</subtitle><entry><title>Dive into Assembly Optimisation for Multiplication</title><link href="https://RoshanStacker.github.io/dive-into-assembly-optimisation-for-multiplication.html" rel="alternate"></link><published>2021-10-16T05:56:00+11:00</published><updated>2021-10-16T05:56:00+11:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2021-10-16:/dive-into-assembly-optimisation-for-multiplication.html</id><summary type="html">&lt;p&gt;This is a bit of research into how multiplying a variable and a constant integer is compiled into assembly x86 instructions. We will look at how the instruction set changes as the constant integer changes.&lt;/p&gt;
&lt;h2&gt;Setup and Scripts&lt;/h2&gt;
&lt;p&gt;We start with a mulk.c file which contains a function that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a bit of research into how multiplying a variable and a constant integer is compiled into assembly x86 instructions. We will look at how the instruction set changes as the constant integer changes.&lt;/p&gt;
&lt;h2&gt;Setup and Scripts&lt;/h2&gt;
&lt;p&gt;We start with a mulk.c file which contains a function that takes a parameter, and returns the parameter multiplied by a constant. This constant can be chosen at compile time using a make file. We can then script a loop to run this make file for a range of values.&lt;/p&gt;
&lt;p&gt;Here are the scripts:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mulk.c&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;mulk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Makefile&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c"&gt;# Set up a default value for K.&lt;/span&gt;
&lt;span class="c"&gt;# To use other values, run make with&lt;/span&gt;
&lt;span class="c"&gt;# # the preferred value of K.&lt;/span&gt;
&lt;span class="c"&gt;# make k=5&lt;/span&gt;
&lt;span class="c"&gt;# make k=7&lt;/span&gt;
&lt;span class="c"&gt;# etc.&lt;/span&gt;
&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="o"&gt;?=&lt;/span&gt;&lt;span class="m"&gt;32&lt;/span&gt;
&lt;span class="c"&gt;# Allow the user to type K=5 or k=5&lt;/span&gt;
&lt;span class="nv"&gt;K&lt;/span&gt;&lt;span class="o"&gt;?=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;k&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="nf"&gt;all&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;@gcc&lt;span class="w"&gt; &lt;/span&gt;-O1&lt;span class="w"&gt; &lt;/span&gt;-S&lt;span class="w"&gt; &lt;/span&gt;-DK&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;K&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;mulk.c&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;mulk&lt;span class="k"&gt;$(&lt;/span&gt;k&lt;span class="k"&gt;)&lt;/span&gt;.s
&lt;span class="w"&gt;        &lt;/span&gt;@cat&lt;span class="w"&gt; &lt;/span&gt;mulk&lt;span class="k"&gt;$(&lt;/span&gt;k&lt;span class="k"&gt;)&lt;/span&gt;.s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This make file simply compiles the code into assembly, then outputs the assembly code.&lt;/p&gt;
&lt;h2&gt;Notes on Assembly&lt;/h2&gt;
&lt;p&gt;For the following snippets of Assembly, I will include on the processing for multiplication. Remember that in Assembly, the %rdi register holds the first parameter passed to the function, which will be &lt;code&gt;a&lt;/code&gt; from the C code. Also the %rax register holds the return value, which will be the result of the multiplication. Using this make file, I can type the command &lt;code&gt;make k=1&lt;/code&gt; to compile with the constant integer 1, and I can replace 1 with any other integer.&lt;/p&gt;
&lt;h2&gt;Multiplying by Small Integers&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=1&lt;/span&gt;

&lt;span class="n"&gt;movq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Since multiplying by 1 returns the input value, this can be done by moving the input value to the output plain and simple.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=2&lt;/span&gt;

&lt;span class="n"&gt;leaq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What &lt;code&gt;leaq&lt;/code&gt; does is evaluate a simple arithmetic expression which contains up to 4 values and denoted by brackets &lt;code&gt;()&lt;/code&gt; in the form &lt;code&gt;Displacement ( Base, Index, Scale)&lt;/code&gt;. This expression equates to &lt;code&gt;= D + B + ( I * S )&lt;/code&gt;. &lt;code&gt;leaq&lt;/code&gt; specifically then moves the result to the second parameter register which is &lt;code&gt;%rax&lt;/code&gt; in this case. This is contrasted by the &lt;code&gt;movq&lt;/code&gt; command which evaluates the expression, then goes to that address in memory and moves the value located there to the second register. The simple arithmetic expression is normally used for array indexing, but also works as a short hand for simple arithmetic while being fast in hardware.&lt;/p&gt;
&lt;p&gt;Evaluating this &lt;code&gt;leaq&lt;/code&gt; gives &lt;code&gt;%rax = %rdi + %rdi&lt;/code&gt; or &lt;code&gt;%rdi * 2&lt;/code&gt;`.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=3&lt;/span&gt;

&lt;span class="n"&gt;leaq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Another &lt;code&gt;leaq&lt;/code&gt;. This one evaluates to &lt;code&gt;%rax = %rdi + (%rdi * 2)&lt;/code&gt;. An interesting question here is comparing &lt;code&gt;leaq&lt;/code&gt; with &lt;code&gt;addq&lt;/code&gt;, because here we have introduced a multiply by 2, and a point of this post is about how multiple is slow and can be optimised, so why do we have &lt;code&gt;leaq&lt;/code&gt; multiplying. It is possible that &lt;code&gt;leaq&lt;/code&gt; actually adds &lt;code&gt;%rdi&lt;/code&gt; twice to compute &lt;code&gt;(%rdi * 2)&lt;/code&gt; to avoid multiplying. You may think that this would be the same as using &lt;code&gt;addq&lt;/code&gt; 2 times, but it is actually different. Because &lt;code&gt;leaq&lt;/code&gt; is for calculating addresses, it is actually done in the decode phase in some modern CPUs thanks to superscalar processors. This is out of the scope for this blog post, but the point is that &lt;code&gt;leaq&lt;/code&gt; is very fast in hardware.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=4&lt;/span&gt;

&lt;span class="n"&gt;leaq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;(,&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Another &lt;code&gt;leaq&lt;/code&gt; which evaluates to &lt;code&gt;0 + 0 + (%rdi * 4)&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=5&lt;/span&gt;

&lt;span class="n"&gt;leaq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;5 uses &lt;code&gt;leaq&lt;/code&gt; as well but only multiplies by 4 and then adds itself to get &lt;code&gt;*5&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=6&lt;/span&gt;

&lt;span class="n"&gt;leaq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;span class="n"&gt;addq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is the first expression to use more than one command. We see the &lt;code&gt;leaq&lt;/code&gt; used for multiplying by 3, and then this result is added to itself to double this, make it &lt;code&gt;3 * 2 = 6&lt;/code&gt;. If we look into why it has done this instead of using &lt;code&gt;leaq 0(,%rdi,6)&lt;/code&gt;, we can make the guess that using &lt;code&gt;leaq&lt;/code&gt; to multiply by 6 could take 6 steps, and using &lt;code&gt;leaq&lt;/code&gt; to multiply by 2 and add 1 would take a total of 3 steps. Then adding this result to itself is a further 1 step for a total of 4 steps, which is less than 6 steps.&lt;/p&gt;
&lt;h2&gt;Hypothesis&lt;/h2&gt;
&lt;p&gt;It seems that first, the compiler favours &lt;code&gt;leaq&lt;/code&gt; very highly. This is backed up by modern CPU hardware optimising &lt;code&gt;leaq&lt;/code&gt; instructions, and these instructions taking place during decoding which can make their processing cost appear 'free'. Second, it seems that &lt;code&gt;leaq&lt;/code&gt; using large numbers to multiply increase the number of steps to compute it, leading to the process seen in &lt;code&gt;k=6&lt;/code&gt; where &lt;code&gt;leaq&lt;/code&gt; is used to compute half of the multiplication, and then adding the result with it self to double it completes the multiplication by 6.&lt;/p&gt;
&lt;p&gt;We are doing multiplication here, yet while there is a specific one line command in assembly for multiplication known as &lt;code&gt;imul&lt;/code&gt; (integer multiply), we haven't seen it. With a basic understanding of binary arithmetic, it makes sense that adding two binary numbers together is fast. Simple half adders and full adders can be creating using a few logic gates per bit, and the process of adding is very close to XORing two registers. While multiplication of two registers is harder because there is no simple way to do it.&lt;/p&gt;
&lt;p&gt;My hypothesis as to why the compiler is not using &lt;code&gt;imul&lt;/code&gt; is because it costs more time or clock cycles in the CPU hardware, and using addition, shifts and &lt;code&gt;lea&lt;/code&gt; would be faster. Therefore we can assign a cost value to each command where &lt;code&gt;imul&lt;/code&gt; is a high cost and &lt;code&gt;addq&lt;/code&gt;, &lt;code&gt;leaq&lt;/code&gt;, &lt;code&gt;sarq&lt;/code&gt; and &lt;code&gt;salq&lt;/code&gt; have low costs. If we the total number of these commands and compare it with the values for &lt;code&gt;k&lt;/code&gt; which the compiler starts to use &lt;code&gt;imul&lt;/code&gt;, we can evaluate the ratio of the costs of these commands.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;code&gt;salq&lt;/code&gt; and &lt;code&gt;sarq&lt;/code&gt; (shift arithmetic left/right) are used to bitshift registers. This can multiply by powers of 2 similarly to how adding a zero to the end of a decimal number will multiply it by 10.&lt;/p&gt;
&lt;h2&gt;Testing with Larger Integers&lt;/h2&gt;
&lt;p&gt;I created a bash script that would compile with values of &lt;code&gt;k&lt;/code&gt; from 1 to 80. It prints out the number of times each command appears in the assembly code for each value of &lt;code&gt;k&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;!/bin/bash

&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;number&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;..80&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;===================&lt;/span&gt;&lt;span class="nv"&gt;$number&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;MUL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;grep&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;imul
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;lea&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;grep&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;lea
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;grep&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;add
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;sub&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;grep&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;sub
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;sal&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;k&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;grep&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;sal
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This reveals that the first time &lt;code&gt;imul&lt;/code&gt; is used is for &lt;code&gt;k=46&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=46&lt;/span&gt;

&lt;span class="n"&gt;imulq&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="no"&gt;$&lt;/span&gt;&lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Using the results for all values between 1 and 80, I calculated the maximum number of commands used. &lt;strong&gt;I found the maximum was 3 commands&lt;/strong&gt;. So I investigated the code for values that are one command away from 46, which would be &lt;code&gt;46/2&lt;/code&gt;, since &lt;code&gt;addq&lt;/code&gt; can be used to quickly double a register.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// For k=23&lt;/span&gt;

&lt;span class="n"&gt;leaq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;span class="n"&gt;salq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="no"&gt;$&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;span class="n"&gt;subq&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;%&lt;span class="n"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;%&lt;span class="n"&gt;rax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Assembly for &lt;code&gt;k=23&lt;/code&gt; uses 3 commands, meaning appending an &lt;code&gt;addq %rax, %rax&lt;/code&gt; would use a total of 4 commands.&lt;/p&gt;
&lt;p&gt;Based on this finding, I believe the compiler is trying to use up to 3 of these simple commands to optimise the multiplication, and using &lt;code&gt;imul&lt;/code&gt; when the minimum number of these simple command is greater than 3.&lt;/p&gt;
&lt;h2&gt;Explaining this Behaviour&lt;/h2&gt;
&lt;p&gt;So based on our assumption that the compiler is assigning costs to these commands, where &lt;code&gt;addq&lt;/code&gt;, &lt;code&gt;leaq&lt;/code&gt;, &lt;code&gt;sarq&lt;/code&gt; and &lt;code&gt;salq&lt;/code&gt; could have costs of &lt;code&gt;1&lt;/code&gt;, then &lt;code&gt;imul&lt;/code&gt; would have a cost of between &lt;code&gt;3-4&lt;/code&gt; as this is where the compiler chooses to use &lt;code&gt;imul&lt;/code&gt; instead of &lt;code&gt;4&lt;/code&gt; simple commands. I started to research the hardware costs of these commands.&lt;/p&gt;
&lt;p&gt;In old CPUs that are simple, this cost would come in the number of clock cycles it takes to evaluate these commands. In modern CPUs, calculating the number of clock cycles probably won't work as modern CPUs would have parallel processing and other optimisations that allow out-of-order processing.&lt;/p&gt;
&lt;p&gt;I found a document assigning costs to assembly commands written by &lt;strong&gt;Agner Fog. from the Technical University of Denmark&lt;/strong&gt;. Found at this link: https://www.agner.org/optimize/instruction_tables.pdf&lt;/p&gt;
&lt;p&gt;For an old CPU like the Intel Pentium, this document shows the clock cycles for each command.&lt;/p&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2021/10/image.png?w=481" class="wp-image-200" style="width:467px;height:81px" /&gt;
&lt;/figure&gt;

&lt;p&gt;This shows that &lt;code&gt;mov&lt;/code&gt; takes 1 clock cycle. It also specifies that &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;sub&lt;/code&gt; and &lt;code&gt;lea&lt;/code&gt; take 1 cycle. It does not include &lt;code&gt;sal&lt;/code&gt; or &lt;code&gt;sar&lt;/code&gt;. For &lt;code&gt;imul&lt;/code&gt; it states 11 clock cycles, making &lt;code&gt;imul&lt;/code&gt; cost 11 times as much as the other simple instructions&lt;/p&gt;
&lt;figure class="wp-block-image size-large"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2021/10/image-1.png?w=480" class="wp-image-202" /&gt;
&lt;/figure&gt;

&lt;p&gt;This supports the idea that &lt;code&gt;imul&lt;/code&gt; costs more than the simple expression resulting in the compiler using multiple simple expressions before using &lt;code&gt;imul&lt;/code&gt;. However, the size of this extra cost is much more than we predict, being &lt;code&gt;11*&lt;/code&gt; instead of &lt;code&gt;3-4*&lt;/code&gt; greater. To work around this, we need to look at tables for modern CPUs which are conveniently provided in this document.&lt;/p&gt;
&lt;p&gt;For a modern CPU, I looked at Intel's 10th gen IceLake CPU released in 2019. Because of complex CPU optimisations to support out-of-order computation, the instructions are not measured in &lt;em&gt;clock cycles&lt;/em&gt; but instead measured in &lt;em&gt;latency&lt;/em&gt;. Latency here refers to time in core clock cycles making it effectively the same as measuring &lt;em&gt;clock cycles&lt;/em&gt;, while accounting for speed improvements due to parallel processing and other optimisations. This is because it measure how long the CPU must wait for the result of the calculation before it can return it, the same idea as &lt;em&gt;clock cycles&lt;/em&gt; in the Pentium&lt;/p&gt;
&lt;figure class="wp-block-image size-large"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2021/10/image-2.png?w=635" class="wp-image-204" /&gt;&lt;br /&gt;

&lt;figcaption&gt;IceLake &lt;code&gt;mov&lt;/code&gt; costs&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class="wp-block-image size-large"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2021/10/image-4.png?w=642" class="wp-image-207" /&gt;&lt;br /&gt;

&lt;figcaption&gt;IceLake &lt;code&gt;lea&lt;/code&gt; costs&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This shows that &lt;code&gt;mov&lt;/code&gt;, &lt;code&gt;lea&lt;/code&gt;, &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;sub&lt;/code&gt;, &lt;code&gt;sar&lt;/code&gt; and &lt;code&gt;sal&lt;/code&gt; all cost around 1 in terms of latency. Compare this is the forms of &lt;code&gt;imul&lt;/code&gt;.&lt;/p&gt;
&lt;figure class="wp-block-image size-large"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2021/10/image-5.png?w=572" class="wp-image-209" /&gt;&lt;br /&gt;

&lt;figcaption&gt;IceLake &lt;code&gt;imul&lt;/code&gt; costs&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;All the forms of &lt;code&gt;imul&lt;/code&gt; cost 3-4 in terms of latency. This supports the measurement of the compiler valuing &lt;code&gt;imul&lt;/code&gt; as 3-4 times slower than the other simple commands.&lt;/p&gt;
&lt;h2&gt;Conclusion and Findings&lt;/h2&gt;
&lt;p&gt;Look at the assembly code created by the compiler, it chooses to use up to 3 simple commands of &lt;code&gt;mov&lt;/code&gt;, &lt;code&gt;lea&lt;/code&gt;, &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;sub&lt;/code&gt;, &lt;code&gt;sar&lt;/code&gt; and &lt;code&gt;sal&lt;/code&gt;. If more than 3 of these commands are required, the compiler will instead use &lt;code&gt;imul&lt;/code&gt;. Researching the speed at which a modern CPU will process these commands shows that &lt;code&gt;imul&lt;/code&gt; does in fact cost 3-4 times as much as the simple commands. It is interesting to not that for an old CPU like the Pentium, this cost was 11 times as much, and modern CPU hardware has reduced this down to only 3-4. We can also explain this as the cost of the simple commands in terms of time (&lt;em&gt;latency&lt;/em&gt;) or &lt;em&gt;clock cycles&lt;/em&gt; have stayed at a value of 1 cycle, while it is &lt;code&gt;imul&lt;/code&gt; which has become cheaper to compute. This points to the simple commands being limited to 1 cycle as this is the fastest anything can run, while innovations such as parallelism and out-of-order calculation has made &lt;code&gt;imul&lt;/code&gt; more efficient.&lt;/p&gt;</content><category term="Post"></category><category term="Assembly"></category><category term="Hardware"></category></entry><entry><title>Co-operation Between AI and Neuroscience Research, and Future Problems</title><link href="https://RoshanStacker.github.io/co-operation-between-ai-and-neuroscience-research-and-future-problems.html" rel="alternate"></link><published>2020-06-01T04:20:00+10:00</published><updated>2020-06-01T04:20:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-06-01:/co-operation-between-ai-and-neuroscience-research-and-future-problems.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Based on an article published in '&lt;/em&gt;Frontiers in Computational Neuroscience&lt;em&gt;' May 6 2020&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Development of Artificial Intelligence (AI) has heavily utilised research done in neuroscience. Neural Networks are a prime example of biological neuroscience research models of neurons being transferred into AI research and development. AI has also aided neuroscience …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Based on an article published in '&lt;/em&gt;Frontiers in Computational Neuroscience&lt;em&gt;' May 6 2020&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Development of Artificial Intelligence (AI) has heavily utilised research done in neuroscience. Neural Networks are a prime example of biological neuroscience research models of neurons being transferred into AI research and development. AI has also aided neuroscience researches in understanding biological brains. However, the diverging goals and applications for neuroscience research and AI research are a threat to the continued synergy between the fields.&lt;/p&gt;
&lt;h2&gt;The Divergence&lt;/h2&gt;
&lt;p&gt;The authors of the article have defined a three axis model of the goals of researchers in the AI and neuroscience fields in order to show the difference. They define research as answering some of the following questions; "what is it?", "how does it work?" and "what does it do?". These can be simplified into understanding the &lt;em&gt;form&lt;/em&gt;, &lt;em&gt;mechanism&lt;/em&gt; or &lt;em&gt;function&lt;/em&gt; respectively.&lt;/p&gt;
&lt;p&gt;Using this model, the authors summarised that most neuroscience research is focused on the &lt;em&gt;form&lt;/em&gt; or &lt;em&gt;what&lt;/em&gt; makes up the brain. Secondary is research into the &lt;em&gt;mechanism&lt;/em&gt; or &lt;em&gt;how&lt;/em&gt; the brain works. The obvious reasons for this stem from the fact that neuroscience can study biological brains which are a physical object the we can learn about, hence &lt;em&gt;form&lt;/em&gt;. Neuroscience also relates to medicine, and would be interested in how the brain works, and what areas of the brain perform what functions. This is so that they can develop treatments for neurological illnesses, hence they are interested in the &lt;em&gt;form&lt;/em&gt; and the &lt;em&gt;mechanisms&lt;/em&gt; in the brain.&lt;/p&gt;
&lt;p&gt;AI research is very different, particularly in the fact that the models are artificial, and development is in the &lt;em&gt;creation&lt;/em&gt; of these models. AI research is also focused at solving particular jobs such as image recognition which is based on &lt;em&gt;function&lt;/em&gt;, making this its primary focus. The secondary focus is the &lt;em&gt;mechanisms&lt;/em&gt; as this reflects how the AI systems work and learn, and this is the information that developers use to create the AI models and artificial neural networks.&lt;/p&gt;
&lt;figure class="wp-block-table is-style-stripes"&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="has-text-align-center" data-align="center"&gt;&lt;strong&gt;Neuroscience&lt;/strong&gt;&lt;/td&gt;
&lt;td class="has-text-align-center" data-align="center"&gt;&lt;strong&gt;Artificial Intelligence&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class="has-text-align-center" data-align="center"&gt;1. &lt;em&gt;Form&lt;/em&gt;&lt;/td&gt;
&lt;td class="has-text-align-center" data-align="center"&gt;1. &lt;em&gt;Function&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class="has-text-align-center" data-align="center"&gt;2. &lt;em&gt;Mechanism&lt;/em&gt;&lt;/td&gt;
&lt;td class="has-text-align-center" data-align="center"&gt;2. &lt;em&gt;Mechanism&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;Primary and Secondary focuses of research in the fields of study&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Importance of Neuroscience for AI&lt;/h2&gt;
&lt;p&gt;Following a formal understanding of the visual cortex in human brains, a precursor neural network to modern day CNNs was able to be created. AI researchers very often explore neuroscience inspired approaches to AI design and modelling. However, history has shown that such a model still needs to provide benchmarked improvements over current models for continued development from AI researchers.&lt;/p&gt;
&lt;p&gt;Neuroscience research is in an exciting era as the technology used to study the brain is become more and more advanced, allowing measurements of more neurons &lt;strong&gt;and&lt;/strong&gt; a larger time frame. Higher resolution and multidimensional data is also able to be analysed more effectively than ever before using new data science and greater computational power. Temporal dynamics seem to play a major role in biological brains and it is now able to be fully observed. With this, neuroscience is on the cusp of a 'complete connectome', which is a full map of the neuron connections in a human brain. This would remove the roadblock in AI research that was the question; "how is the human brain wired?".&lt;/p&gt;
&lt;p&gt;Tasks for a computer can be divided into two categories, those that a human is better at, and those that a computer is better at. AI has always been focused on tasks a human is better at, and has been looking at ways to improve the computer at said task. Neuroscience research is often learning about these tasks that a human can beat a computer at, however, there is no perfect understanding of the human brain in this field which limits the ways in which AI can improve from neuroscience. Understanding of the brain in these tasks, when there is any, can sometimes come from macro understandings of function, such as understandings of memory. This is disconnected from the physical neural circuitry. As said before, AI research could benefit from better &lt;em&gt;functional&lt;/em&gt; and &lt;em&gt;mechanical&lt;/em&gt; understanding, but the lack of &lt;em&gt;mechanical&lt;/em&gt; understanding of these areas is very limiting. This is combined with the &lt;em&gt;functional&lt;/em&gt; understanding being unproven and split into multiple plausible theories for the same task. There is a divide in near-future neuroscience research, as the tools look into an understanding of &lt;em&gt;form&lt;/em&gt; and &lt;em&gt;mechanics&lt;/em&gt;, but do not look at &lt;em&gt;function&lt;/em&gt;. This divide is a major challenge and creates the difficulties in the continued co-operation between neuroscience and AI.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;For future "cross-pollination" between neuroscience and AI research, it would be very effective for a shift in communication. Neuroscience can extrapolate their understanding of form and mechanics of the brain towards the implementation of the mechanics into artificial neural networks. This can be extrapolated to the function of the system which would represent the goals of an AI model. Doing this is likely to significantly aid in the future development of AI particularly in tasks were humans out perform computers, and neuroscience is an effective source of new approaches.&lt;/p&gt;
&lt;div class="wp-block-spacer" style="height:100px;" aria-hidden="true"&gt;

&lt;/div&gt;

&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Subject paper: "Crossing the Cleft: Communication Challenges Between Neuroscience and Artificial Intelligence",&lt;br&gt;
&lt;a href="https://doi.org/10.3389/fncom.2020.00039"&gt;https://doi.org/10.3389/fncom.2020.00039&lt;/a&gt;  &lt;/p&gt;</content><category term="Post"></category><category term="Artificial Intelligence"></category><category term="Neuroscience"></category></entry><entry><title>Encrypting Files and Not Trusting Cloud Storage Providers</title><link href="https://RoshanStacker.github.io/encrypting-files-and-not-trusting-cloud-storage-providers.html" rel="alternate"></link><published>2020-05-28T06:38:00+10:00</published><updated>2020-05-28T06:38:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-05-28:/encrypting-files-and-not-trusting-cloud-storage-providers.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Based on 2003 paper from HP Labs and published in FAST&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;How can we make full use of cloud storage providers and online file sharing, while also protecting our data when we can't trust the big companies providing the cloud storage? The answer is end-to-end encryption and forced no-knowledge storage …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Based on 2003 paper from HP Labs and published in FAST&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;How can we make full use of cloud storage providers and online file sharing, while also protecting our data when we can't trust the big companies providing the cloud storage? The answer is end-to-end encryption and forced no-knowledge storage. The best part is that you can have your cake and eat it too, since this paper shows ways to incorporate the simple file sharing mechanisms popularised in google docs and drive, and the encryption.&lt;/p&gt;
&lt;h2&gt;The Problem and the Threat Model&lt;/h2&gt;
&lt;p&gt;We are using this system primarily due to the lack of trust of the server. More specifically, we do not trust the server to keep the files confidential and not skim over them. However, as the data is still stored on the servers, we must trust they do not simply destroy the data entirely. To get around this, a user could implement multiple server providers and copy the same techniques there.&lt;/p&gt;
&lt;p&gt;Trust is required in the client's machine where the encryption and other execution is done. This may lack perfect trust due to viruses and other malware, but this is nessesary and would be for almost any cryptographic and security system. There is also trust placed on the key exchanges and distribution as the client will have full control over the keys. This trust system and threat model is perfect though, since almost all trust is put under the direct control of the user, and away from storage providers.&lt;/p&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;Encrypting files is the first step in the solution, but it would be very inefficient to encrypt every file separately. File groups are used where the entire group has the same symmetric encryption key. These file groups are different to file folders and do not have anything to do with file hierarchy. Files have their file group defined in their meta data which allows a small number of groups that reflect who has access to the files, rather than the location of the files in the hierarchy. A small number of file groups, and therefore keys, is important as key distribution and control is done entirely by the user, meaning less keys is very useful for reducing user side overheads.&lt;/p&gt;
&lt;p&gt;To achieve a differentiation between read permissions and writing permissions, asymmetric keys are used. The contents of encrypted files are put through a hash function and signed using a private RSA key. This signing can be verified using the public RSA key. As such, the public RSA key can be given to those for reading, and the private key is kept for writers.&lt;/p&gt;
&lt;p&gt;A final major problem is revoking access from users. When the server is trusted, this is easily done using user authentication. This is not feasible when the server is not trusted as the server would, in general, need the ability to access the information in order to give that ability to specific users. The server would also cache information, particularly about the users, which is trusting the server with more information than is ideal. The solution is to use key rotation. Keys will change over time, and given the latest keys, a user can generate all previous key versions. Only the owner can generate the future keys. With these properties, a user can lose access if the owner does not send new keys. This is &lt;em&gt;lazy revocation&lt;/em&gt; as the user still has access to the files from the past, but this maintains forward secrecy which is the primary security concern. Accepting this shortcoming avoids a significant amount of computational time as each revocation would require a complete re-encryption of all files. Instead, re-encryption is simply done on the next update of the file.&lt;/p&gt;
&lt;p&gt;Revoking read privileges versus write privileges relates to revoking the verification RSA key for readers, and the signing RSA key for writers. A problem is that writers have the ability to sign new files, and would hold the next key in the key rotation. To avoid expensive re-encryption when writers lose their privilege, the meta data of files can be updated immediately as a low cost and mostly effective security measure. Data writes can also be validated by the server using an access control list which is effectively like a shared password for writing. This would blocked most updates from revoked writers, however there still remains some attacks where a revoked writer makes changes that can fool a reader with keys that are out of date. The only way to block these revoked writer problems with with aggressive key changes, but this effort may not be worth it if the users' risk appetite is moderate enough.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The final Plutus file system is quite simple and is cryptographically effective at providing user roles and blocking the server from knowledge of the files. In the paper, the researchers evaluate the performance and showed that it was as good if not better than comparable and popular methods that encrypt the transmission of data to the server and trust the server. Take note that is paper is from 2003. A major update would be to use AES for symmetric encryption instead of triple DES as done in the paper.&lt;/p&gt;
&lt;p&gt;A final point that makes the system very practical is the scalability. As cryptographic overhead is performed almost entirely on the client's side, and key distribution is done by the client, the server does not expended extra computational power. As such, this can be implemented and server owners will not see an added cost, which means they should premise this system for use on their servers. This overhead place on the user also allows the size of the storage space used to grow and grow without having a compounding impact of the server and extra space required. The Plutus file system seems to be a very effective and cryptographically secure way to store files and collaborate without trusting the server where the files are stored.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Subject Paper: "&lt;strong&gt;Plutus: Scalable secure file sharing on untrusted storage&lt;/strong&gt;", Mahesh Kallahalla, Erik Riedel, Ram Swaminathan, Qian Wang, Kevin Fu,&lt;br&gt;
https://www.usenix.org/legacy/event/fast03/tech/full_papers/kallahalla/kallahalla_html/&lt;/p&gt;</content><category term="Post"></category><category term="Cryptography"></category></entry><entry><title>Unexpected Security Flaws in the use of Diffie-Hellman</title><link href="https://RoshanStacker.github.io/unexpected-security-flaws-in-the-use-of-diffie-hellman.html" rel="alternate"></link><published>2020-05-25T11:45:00+10:00</published><updated>2020-05-25T11:45:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-05-25:/unexpected-security-flaws-in-the-use-of-diffie-hellman.html</id><summary type="html">&lt;h2&gt;The miraculous Diffie-Hellman key exchange&lt;/h2&gt;
&lt;p&gt;Published in 1976, the Diffie-Hellman key exchange demonstrated a method for two parties to generate a shared secret key across a public network where anyone eavesdropping on the entire exchange will have trouble learning the shared secret. The whole exchange can be achieved in 3 …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;The miraculous Diffie-Hellman key exchange&lt;/h2&gt;
&lt;p&gt;Published in 1976, the Diffie-Hellman key exchange demonstrated a method for two parties to generate a shared secret key across a public network where anyone eavesdropping on the entire exchange will have trouble learning the shared secret. The whole exchange can be achieved in 3 messages. The diagram below shows what variables are sent over the public domain, meaning an eavesdropper will know the public variables.&lt;/p&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2020/05/diffie-hellmankeyexchangediagram.png?w=399" class="wp-image-114" width="739" height="432" /&gt;&lt;br /&gt;

&lt;figcaption&gt;a and b = secret number, g is any number, p is a large prime size 512|768|1024|2048 bits&lt;br /&gt;
ga is (g&lt;sup&gt;a&lt;/sup&gt;)mod p&lt;br /&gt;
gab is (g&lt;sup&gt;ab&lt;/sup&gt;)mod p&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Breaking Diffie-Hellman will require the attacker to compute &lt;em&gt;gab&lt;/em&gt; given &lt;em&gt;g, p&lt;/em&gt; and &lt;em&gt;ga&lt;/em&gt;/&lt;em&gt;gb&lt;/em&gt;. An attacker can do the last step that one of sides performs if they can find the secret &lt;em&gt;a&lt;/em&gt; or &lt;em&gt;b&lt;/em&gt;. However, the key exchange is secure due to the difficulty in reversing the calculation that is done to combine &lt;em&gt;g&lt;/em&gt; and &lt;em&gt;a&lt;/em&gt;/&lt;em&gt;b&lt;/em&gt; (&lt;em&gt;g&lt;sup&gt;a&lt;/sup&gt; mod p&lt;/em&gt;). In mathematics, reversing the calculation is known as solving the discrete logarithm problem. The amount of difficulty in breaking this security is closely related to be the size of the prime number &lt;em&gt;p&lt;/em&gt;. The common sizes of primes are 512 bit, 768 bit, 1024 bit and 2048 bit (as larger primes have a disproportional cost of performance to security gain). The problem that the paper and this blog will discuss is how 512, 768 and potentially 1024 bit key exchanges could be broken on the fly given a substantial (and expensive) but plausible amount of pre-calculation on designated prime numbers.&lt;/p&gt;
&lt;h3&gt;Export grade Diffie-Hellman instead of 'Military Weapons Grade' (Why we use 512 bit)&lt;/h3&gt;
&lt;p&gt;Around 1990s, the US government declared the intellectual property of some strong encryption methods to be 'military weapons grade', which included Diffie-Hellman key exchanges that used more than 512 bits. As a result, if an algorithm or code was published and reached outside the US, the authors would be committing the crime of 'exporting military grade weapons'. From this, 512 bit Diffie-Hellman is known as DHE-EXPORT as it can be export. These restrictions no longer apply, but the 512 bit system is in use in some cases for the purpose of backwards compatibility.&lt;/p&gt;
&lt;h2&gt;Breaking Diffie-Hellman (through pre-computation)&lt;/h2&gt;
&lt;p&gt;As the design of Diffie-Hellman is based around the difficulty of solving the discrete log problem (reversing the calculation that each side makes), the best method of attack for an eavesdropper is to do just that. One of the most efficient algorithms to perform this calculation is known as the number field sieve (NFS) algorithm. It takes a very long time to compute this algorithm for the large prime that are used today, meaning it is impossible to use it in real time. What the researchers have shown is that they are able to pre-compute using a specific prime number &lt;em&gt;p&lt;/em&gt;, and after 3 steps, create a logarithm database that stores the results of the computations and allows a 4th step to take the input of a shared key in the Diffie-Hellman exchange (&lt;em&gt;gb&lt;/em&gt;/&lt;em&gt;ga&lt;/em&gt;) and find the solution in around a minute by looking through the database. This means that not only is it possible to break new key exchanges in effectively real-time, but the pre-computation can be transferred, kept or sold.&lt;/p&gt;
&lt;p&gt;This method of pre-computation to create a database for a single prime number is still a very long process. Researchers with 'academic-level' computational resources managed to solve for a 512 bit prime within a week back in 2015, and with modern hardware and improved software, they can compute a prime in just 2 days. Their 2015 system was made up of 2000-3000 microprocessor cores. The size of this would be beyond an individual but well within the range of larger academic teams and certainly nation states. Beyond 512 bits, the researchers also determined that 768 bit primes could be broken by academic teams with even more time for each prime, and they concluded that given millions in funding, nation states could break a single 1024 bit prime every year. There is evidence from the leaks on the NSA, that they had cracked 1024 bit Diffie-Hellman allowing them to decrypt some VPN traffic.&lt;/p&gt;
&lt;h2&gt;Just use a different prime...&lt;/h2&gt;
&lt;p&gt;The pre-computations take a long time and only give you a database for a single prime number, but the widespread implications of this are severe when you begin to look at how most servers implement Diffie-Hellman in practice. In a 2015 scan of 529,000 HTTPS sites, 68.3% were found to use Diffie-Hellman, and 8.4% used 512 bit (DHE-EXPORT). Of these sites that use 512 bit primes, 82% used the same prime, and another 10% used a second prime. They are the default for Apache and '&lt;em&gt;mod_ssl&lt;/em&gt;' respectively. This means that an attacker could perform pre-calculation on just 2 primes, and be able to attack around 92% of websites that use 512 bit Diffie-Hellman.&lt;/p&gt;
&lt;p&gt;Safe primes are important in order to maintain security, which is defined as a prime where &lt;em&gt;(p-1) / 2&lt;/em&gt; is also a prime. Finding safe primes that are of the size required can be computationally difficult, which is why most implementations use a publicly known safe prime, such as those in the Oakley groups. As a result, most implementations of Diffie-Hellman have ended up using the same primes meaning that this pre-computation attack, although initially computationally expensive, can have widespread use in the many servers that use the most common primes.&lt;/p&gt;
&lt;p&gt;For efficiently, servers typically use the same secret value for all their key exchanges in order to avoid time calculating based on new private parameters. This should not have a significant effect of security as the client still uses a new secret value every time (however this can be used as discussed later). This use of at least on &lt;em&gt;new&lt;/em&gt; secret value every time is call being '&lt;em&gt;ephemeral&lt;/em&gt;', and enables &lt;em&gt;forward secrecy&lt;/em&gt;. Some servers such as Microsoft change this value every 2 hours, but multiple key exchanges are still done using the same server-held secret value.&lt;/p&gt;
&lt;h2&gt;Downgrading higher bit implementations back to 512 bit&lt;/h2&gt;
&lt;p&gt;In Transport Layer Security (TLS), a handshake occurs between the client and the server to decide which cryptographic system will be used i.e. regular DHE or DHE-EXPORT. A client sends their list of supported methods which allows for a Man in the Middle attack (MITM) to downgrade their connection to use DHE-EXPORT (which is 512bit) every time. This is done by hijacking the client's message to ask for DHE-EXPORT to be used instead of DHE, and then simply eavesdropping on the parameters (&lt;em&gt;g&lt;/em&gt;, &lt;em&gt;p&lt;/em&gt; and &lt;em&gt;gb&lt;/em&gt;) which the sever sends to the client for the key exchange. Given the &lt;em&gt;p&lt;/em&gt; which the attacker has used in the pre-computation, and the &lt;em&gt;g&lt;/em&gt; and &lt;em&gt;gb&lt;/em&gt; values, it is possible to find the value of &lt;em&gt;b&lt;/em&gt; within a minute or so. The researchers were able to perform this within an average of 70 seconds (ranging from 34 - 206 seconds). When &lt;em&gt;b&lt;/em&gt; is known, the attacker can block the server, or continue to passively eavesdrop and wait for the client to send &lt;em&gt;ga&lt;/em&gt;, and then find the secret private key &lt;em&gt;gba&lt;/em&gt; that is used for encryption/decryption of messages for the rest of the session.&lt;/p&gt;
&lt;p&gt;Some systems have time-outs that require the MITM do the computation quickly and potentially in under the minute that is possible with the pre-computation method. In this case, the fact that some servers use the same secret value &lt;em&gt;b&lt;/em&gt; for multiple different handshakes, an attack can hijack one handshake to calculate &lt;em&gt;b&lt;/em&gt;, and then use &lt;em&gt;b&lt;/em&gt; for future handshakes. However, many systems have a workaround such as Firefox's alerts that reset the timer, and some systems have a long or non-existent time-out for responses.&lt;/p&gt;
&lt;p&gt;For attacks on 768 bit, and potentially 1024 bit, where pre-computation has been done (with a larger cost of time and resources), the resulting lookup of the database that is create will take even longer than a database for a 512 bit prime. So utilising the method of cracking the server's private key in one handshake that will time-out, and then using the private key to crack a new handshake in real-time is important.&lt;/p&gt;
&lt;h2&gt;Summary of the Attack&lt;/h2&gt;
&lt;p&gt;Step 1: Pre-compute a given prime number that the target server uses, for 512 bit primes, this can be done in just a few days using academic level resources. For 1024 bit primes, a nation state could reasonably crack one prime in a year. The result of this pre-computation is a logarithm database for the given prime.&lt;/p&gt;
&lt;p&gt;Step 2: Start a Man in the Middle attack in order to hijack the clients request to use regular DHE, and change it to request 512 bit DHE-EXPORT if possible.&lt;/p&gt;
&lt;p&gt;Step 3: Read the server's response that includes the values &lt;em&gt;g&lt;/em&gt;, large prime &lt;em&gt;p&lt;/em&gt;, and server public key &lt;em&gt;gb&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Step 4: Use values &lt;em&gt;g&lt;/em&gt; and &lt;em&gt;gb&lt;/em&gt; to lookup the pre-computed database and find the corresponding server secret value &lt;em&gt;b&lt;/em&gt;. This takes around a minute for 512 bit primes when using academic level resources and may time-out a connection.&lt;/p&gt;
&lt;p&gt;Step 4.5: If the MITM attack failed due to a time-out, use the now calculated &lt;em&gt;b&lt;/em&gt; value in a new handshake.&lt;/p&gt;
&lt;p&gt;Step 5: Read the clients calculated &lt;em&gt;ga&lt;/em&gt; values and combine it with the known &lt;em&gt;b&lt;/em&gt; value to find the secret key &lt;em&gt;gab&lt;/em&gt; that was exchanged. Now you can decrypt messages until the session ends.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Subject Research Paper: "https://doi.org/10.1145/2810103.2813707",&lt;/p&gt;
&lt;p&gt;Computerphile youtube:&lt;br&gt;
https://www.youtube.com/watch?v=NmM9HA2MQGI&amp;amp;&lt;br&gt;
https://www.youtube.com/watch?v=Yjrfm_oRO0w&lt;/p&gt;
&lt;p&gt;Textbook: "Network Security, Private Communication in a Public World" p.g. 166-167, Second Edition, Charlie Kaufman, Radia Perlman, Mike Speciner  &lt;/p&gt;
&lt;p&gt;https://tls.mbed.org/kb/cryptography/ephemeral-diffie-hellman&lt;/p&gt;</content><category term="Post"></category><category term="Cryptography"></category><category term="Cybersecurity"></category></entry><entry><title>Privacy and a New "Paradoxical" Solution to Digital Signature Security</title><link href="https://RoshanStacker.github.io/privacy-and-a-new-paradoxical-solution-to-digital-signature-security.html" rel="alternate"></link><published>2020-05-17T05:11:00+10:00</published><updated>2020-05-17T05:11:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-05-17:/privacy-and-a-new-paradoxical-solution-to-digital-signature-security.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Based on the paper "A “Paradoxical” Solution to the Signature Problem" by researchers at MIT.&lt;br&gt;
See references for more information&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is impossible to live an efficient life in the technology space without having data stored online in cloud services, email accounts or even online bank accounts. The internet makes …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Based on the paper "A “Paradoxical” Solution to the Signature Problem" by researchers at MIT.&lt;br&gt;
See references for more information&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is impossible to live an efficient life in the technology space without having data stored online in cloud services, email accounts or even online bank accounts. The internet makes using technology extremely useful with all the cloud sharing between devices from desktops to laptops to smart phones. But given this, I feel that privacy is extremely important and I strive to control the security of any data I store online, including using proton mail for no-knowledge encryption in my emails, or manual encryption of files before backing up to google drive.&lt;/p&gt;
&lt;p&gt;A new problem being solved in digital security is the signature problem.&lt;/p&gt;
&lt;h2&gt;The Signature Problem&lt;/h2&gt;
&lt;p&gt;When communicating digitally over the internet, it is very easy for transmissions to be intercepted which is why encryption is very important and a major focus of militaries and intelligence agencies around the world. Encryption uses secret information on both sides of communication to allow the messages sent online and public information sent alongside the messages to be seen by anyone, but requires the secret information to be read, keeping the messages private. A step beyond this is to add some extra information that lets any receiver of the message to be certain as to who the message came from, this is known as a digital signature.&lt;/p&gt;
&lt;p&gt;What makes digital signatures different from encryption is that for encryption, public information with the message should not give any information to attackers. While for digital signatures, public information and the message can allow anyone to verify that the message was indeed sent from the person with the digital signature. What digital signatures must not allow is for the public information to allow attackers to forge the signature on their own messages.&lt;/p&gt;
&lt;h2&gt;Attacks on Signatures and the "Paradox"&lt;/h2&gt;
&lt;p&gt;A successful attack on a signature is achieved when the secret information is learnt, enabling the attacker to forge the signature on new messages, or if the attack can create an efficient algorithm that can create an equivalent signature, enabling forgery. The two main attacks to achieve this forgery are brute force attacks and chosen message attacks. Brute forcing is simply guessing and checking the secret information until the guess turns out to be correct. In most cases, the algorithms for encryption and signing are public knowledge, so guessing and checking is easy. This attack can also use the public key as information to help the guessing. The difficulty comes from the length of the private keys. More effective attacks are chosen or known message attacks. These attacks use knowledge of the message to break the signature. These attacks can be more effective in a so called "adaptive chosen message attack", where the attackers can choose a custom message based on the public key and based on previous messages.&lt;/p&gt;
&lt;p&gt;The paradox, as the paper explains, is a "folklore" in the cryptography community rather than a mathematically proven paradox. It states that it is impossible for the following two statements to be true at the same time in a signature encryption method:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Forging a signature using public information is equivalent to factoring the private keys.&lt;br&gt;
&lt;/em&gt;&lt;em&gt;and&lt;/em&gt;&lt;em&gt;&lt;br&gt;
An adaptive chosen message attack does not benefit from knowledge of previously signed messages.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A simplified reason for this paradox is that for a signature scheme designed with a trap-door function that makes reversing the scheme equivalent to factoring the number, an attacker can choose a message that represents a mathematical value such as a square number. When the attacker receive this message once it has been signed, they are significantly closer to finding the secret values which means that forging in not equivalent to factoring with the use of adaptive chose message attacks.&lt;/p&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;What the researchers have done is what they call a &lt;em&gt;claw-free family&lt;/em&gt; which is using not one trap door function, but two.&lt;/p&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2020/05/image1.png?w=400" class="wp-image-104" width="213" height="213" /&gt;
&lt;/figure&gt;

&lt;p&gt;As shown in the diagram above, the functions f&lt;sub&gt;0&lt;/sub&gt; and f&lt;sub&gt;1&lt;/sub&gt; have directions which represent the trap door functions, where calculating with X or Y inputs is easy, but calculating X or Y from the result ( f&lt;sub&gt;0&lt;/sub&gt;(x) or f&lt;sub&gt;1&lt;/sub&gt;(y) ) is very difficult. The added complexity in this model going from one key (X) to two keys (X, Y) and two trap door functions (f&lt;sub&gt;0&lt;/sub&gt;,f&lt;sub&gt;1&lt;/sub&gt;), results in attackers who know what the functions are, and who know what the result is, cannot easily find X or Y. More crucially, chosen/known message attacks and attacks using the public keys do not gain an advantage in finding X and Y. This proposes a solution to the paradox where calculating the functions in reverse is as difficult as factoring, and preventing public information, including the content of the messages, from being useful to attackers.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;"&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3335741.3335753"&gt;A" paradoxical" solution to the signature problem&lt;/a&gt;"&lt;br&gt;
Shafi Goldwasser, Silvio Micali, Ronald L Rivest  &lt;/p&gt;</content><category term="Post"></category><category term="Cryptography"></category><category term="Cybersecurity"></category></entry><entry><title>Emotional Artificial Intelligence by Simulating Neurotransmitters in the Brain</title><link href="https://RoshanStacker.github.io/emotional-artificial-intelligence-by-simulating-neurotransmitters-in-the-brain.html" rel="alternate"></link><published>2020-05-07T05:04:00+10:00</published><updated>2020-05-07T05:04:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-05-07:/emotional-artificial-intelligence-by-simulating-neurotransmitters-in-the-brain.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Based on a paper from Kazan Federal University, Russia&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Emotional Model: Lovheim cube and Tomkins&lt;/h2&gt;
&lt;p&gt;While there is no perfect and agreed upon model of human emotions, a very promising and simple enough to implement model is Lovheim's cube of emotions. The cube explains 8 of the 9 emotional states …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Based on a paper from Kazan Federal University, Russia&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Emotional Model: Lovheim cube and Tomkins&lt;/h2&gt;
&lt;p&gt;While there is no perfect and agreed upon model of human emotions, a very promising and simple enough to implement model is Lovheim's cube of emotions. The cube explains 8 of the 9 emotional states (affects) that are defined in Tomkins' 'affect theory' of emotions which list distinct emotions such as joy, surprise and disgust. Lovheim's cube uses a 3-dimensional vector to create a resultant emotional state, where the 3 dimensions are given by a quantity neuromodulators (or neurotransmitters) in a person's brain. This theory is based on research that shows the three mono-amine neuromodulators of dopamine, serotonin and noradrenaline. These neuromodulators are responsible for all behavioural control in humans and other animals from lobsters to mice. Lovheim points to evolutionary conservation of this behavioural control system as a strong sign that it is very important for such a system to exist as "&lt;em&gt;[t]he environment an organism encounters is very complex, therefore, a system of behavioural control cannot&lt;br&gt;
be specific to every possible situation.&lt;/em&gt;" Meaning that organisms need behavioural control that is &lt;em&gt;general&lt;/em&gt; and that neuromodulators are an effective generalised system for behavioural control. Lovheim also points to effective behavioural drugs targeting the neuromodulators and the system such as antidepressants and anti-psychotics.&lt;/p&gt;
&lt;p&gt;The cube shows that a vector from one vertex, generated using the quantity of the 3 neuromodulators will point towards a vertex where each vertex corresponds to a emotional state or affect. It may then be possible to quantify the strength of the emotion and combine a mixture of multiple emotions as a point within the cube. It can also define a state where the emotion can freely change in any direction, become stronger, weaker, or changing. This model is also very simple for application in a simple AI where having distinct emotional states is useful for tone and facial posture in a conversation.&lt;/p&gt;
&lt;figure class="wp-block-image size-large"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2020/05/image-1.png?w=680" class="wp-image-82" /&gt;&lt;br /&gt;

&lt;figcaption&gt;Lovheim's cube of emotions&lt;br /&gt;
Source: "A new three-dimensional model for emotions and monoamine neurotransmitters" - Hugo Lovheim in Medical Hypotheses 78 (2012) 341–348&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Making the AI&lt;/h2&gt;
&lt;p&gt;There already exists voice assistants such as Amazon Alexa and IOS Siri, which have the components of speech recognition and speech synthesis, that overlay a simple Q&amp;amp;A system. Current voice assistants are very limited to simple requests and information questions alongside a few pre-programmed responses. The next levels in developing voice assistants and AI such as the one described in the paper, is to add more features including context awareness and emotional reaction. Effective AI assistants would be able to recognise emotions in the voice of the user, which can create a more natural feeling to conversation, and may enable the AI to interpret things like sarcasm. Speech recognition and synthesis have been sufficiently developed as seen in current voice assistants, where the next step is adding emotions into the recognition and synthesis, which would require emotional states to be built into the AI and it's response generation.&lt;/p&gt;
&lt;p&gt;Achieving this next level in AI can potentially be achieved by replicating the cognitive processes that people use in conversation. This includes; memory, decision making, perception, understanding, judgement making, language and emotion. Development for these features is steady but they are not the only roadblocks to more realistic human-machine interfaces. It could be very useful to add a facial interface for the AI to aid in conveying emotions, while also tracking the face of users for detecting emotions. Using the 8/9 affects of the Tomkins model and Lovheim's cube, it is possible to present a face for the AI that is capable of emoting, but the major barrier that is left is the uncanny valley. The uncanny valley by definition is when the artificial animation is so close to real that it is very difficult to critique what is unconvincing, but it is unconvincing nonetheless. The problem that plagues AI in this sense the the creepy feeling that users feel and the inability to trust the agent that is in the uncanny valley. Answers to this problem are yet to be found and the researchers state that more research into the uncanny valley affects on users is needed.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Ultimately the research is very brief which may show that the model with the emotions was not a significant improvement. However, the conclusions on what needs to be done for the improvement of AI, being adding emotions to the input and output as well as the AI thought process, seems to be a fair subject for further development. It still remains that scientific research into human emotions in terms of psychology and physiology are inconclusive, and attempts to model AIs off human emotions could be effective, but the models may need to be too complicated or wait for some new and more promising model of emotions. Lovheim's cube using a vector of 3 chemicals in the brain is very attractive for programming and seems like an effective start, but might be too simple for an AI to climb out of the uncanny valley.&lt;/p&gt;
&lt;div class="wp-block-spacer" style="height:100px;" aria-hidden="true"&gt;

&lt;/div&gt;

&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Subject Paper: "Anthropomorphic Artificial Social Agent with Simulated Emotions and its Implementation", Vlada Kugurakova, Maxim Talanov, Nadir Manakhov, and Denis Ivanov, Procedia Computer Science, Volume 71, 2015, Pages 112–118&lt;br&gt;
https://doi.org/10.1016/j.procs.2015.12.217&lt;/p&gt;
&lt;p&gt;"A new three-dimensional model for emotions and monoamine neurotransmitters", Hugo Lövheim, Medical Hypotheses 78 (2012) 341–348&lt;/p&gt;</content><category term="Post"></category><category term="Artificial Intelligence"></category><category term="Neuroscience"></category><category term="Voice Assistant"></category></entry><entry><title>Machine Learning CNN to Interpret Brain Signals</title><link href="https://RoshanStacker.github.io/machine-learning-cnn-to-interpret-brain-signals.html" rel="alternate"></link><published>2020-05-03T10:14:00+10:00</published><updated>2020-05-03T10:14:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-05-03:/machine-learning-cnn-to-interpret-brain-signals.html</id><summary type="html">&lt;h2&gt;Why Machine Learning can be Effective at Reading the Brain&lt;/h2&gt;
&lt;p&gt;Machine learning has the unique capability to recognise patterns and structures. With this, machine learning has been extremely effective in image &amp;amp; video processing to detect patterns and structures, such as objects or people's faces. As machine learning is developed from …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Why Machine Learning can be Effective at Reading the Brain&lt;/h2&gt;
&lt;p&gt;Machine learning has the unique capability to recognise patterns and structures. With this, machine learning has been extremely effective in image &amp;amp; video processing to detect patterns and structures, such as objects or people's faces. As machine learning is developed from large data sets, it is possible to control the dataset which is used in the learning. The large amount of data required can be a downside for some applications, and can have unexpected negative effects (such as racial biases), but for application in reading brain signals, there are large volumes of data, and the algorithm can learn on an individual person's brain to become more effective at identifying patterns unique to that individual.&lt;/p&gt;
&lt;p&gt;In the paper that is referenced, they have used machine learning to interpret electro-encephalographic (EEG) and magneto-encephalographic (MEG) which are comprised of several hundred sensors around the head to measure activity in regions of the brain and changes over time. The measurements made are multidimensional and are made at a frequency that is less than a millisecond, which creates the large amounts of data that can be used in machine learning. Due to the high-dimensional nature and general complexity of the data, machine learning is a perfect tool to interpret the information, and is more favourable compared to a hard coded algorithm. One new challenge in the application of machine learning in this area is the very low signal to noise ration (SNR). This is because there is a lot of signals measured in the brain that are not related to thought or sensors. This includes blood pumping through the brain and other unconscious actions such as cardiac and background vision. This low SNR poses a problem in any algorithms aiming to interpret brain activity, but may be effectively solved with machine learning.&lt;/p&gt;
&lt;h2&gt;The Algorithms (Convolutional Neural Networks)&lt;/h2&gt;
&lt;p&gt;The authors of the paper have created two separate convolutional neural networks (CNNs) from the t*n tensor of t time and n sensor readings. After some operations on this tensor, they created the LF-CNN and the VAR-CNN where LF-CNN is simple enough to be analysed so that researchers can see what areas of the brain the algorithm is looking at to determine what the person is sensing/thinking of. This was one of the goals of the paper; to be able to compare the model generated with machine learning, and the model generated by neuroscience research, in terms of what areas of the brain correspond to types of inputs. The second VAR-CNN is more complicated and does not allow the same level of observation, however the results showed that it is more accurate in the tests that were performed in the study.&lt;/p&gt;
&lt;h2&gt;The Tests&lt;/h2&gt;
&lt;p&gt;Experimenters used the algorithm in 4 distinct experiments. The first involved 7 subjects experiencing 5 different types of sensory inputs (5 class test) consisting of left or right visuals, audio and finally a shock in the left or right wrist. A large dataset was generated as each subject contributed on average 1622 tests. This dataset was used heavy pre-processing that removed magnetic field interference, head movement, cardiac and ocular interference and more. All this pre-processing would make it impossible for use in real-time and brain computer interfaces (BCI). The results for this first experiment are further elaborated on in the paper, but the results showed that the two CNN models created by the authors out performed existing machine learning algorithms using CNN and SVM models. Previous accuracy scores averaged 93% to 85%, the simpler LF-CNN scored an average of 95.0% with the more complex VAR-CN scoring 95.8%. For tests done with pseudo-real-time constraints, previous systems scored around 85% - 90% while the new models scored 93-94%. This shows that with clean data, the new algorithms have better accuracy which is closing in on 100%, which is impressive for a complex test with 5 classes of inputs.&lt;/p&gt;
&lt;p&gt;Tests 2 and 3 are very similar and have great implications for BCIs. The tests involved subjects imagining moving their hands, either left or right, without actually moving them. Test 2 including a rest condition where subjects did not imagine moving a hand. This data also underwent very light processing that was done in real time, and did not remove artefacts like head movement or cardiac signals. The results of test two showed consistent improvement again with the new models scoring 84% and 86% on average compared to previous models only scoring between 70% and 80%. For the pseudo-real-time test, the new models did not have such a significant improvement only scoring 78% and 82% compared to the EEGNet-8 model scoring 80%. The range of scores in this test are also substantially wider in this test compared to test 1, meaning the results can sometimes be substantially more accurate or less accurate.&lt;/p&gt;
&lt;p&gt;Test 3 was run in real-real-time with the subjects imagining moving one of their hands. Only the more complex VAR-CNN model was used, and the test was run 3 times on a subject where the model would update itself with learning as it was running. The results table from the paper is shown below. While the sample size is very small, the data shows that the model can become more accurate when it can update as it running. This is a very interesting point which demonstrates that it is possible to have machine learning algorithms act as a BCI in real time, and become more accurate as they train themselves on a single individual.&lt;/p&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;
&lt;img src="https://stackingroshan.wordpress.com/wp-content/uploads/2020/05/image.png?w=622" class="wp-image-73" width="776" height="213" /&gt;&lt;br /&gt;

&lt;figcaption&gt;From "Adaptive neural network classifier for decoding MEG signals" page 431&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Test 4 used Cam-CNN which is a 2-class dataset that is publicly available. The data is from 250 subjects with 120 reading per person. The data is either auditory stimuli or visual stimuli using left and right sides simultaneously. This data had the same light processing as tests 2 and 3. Researchers from the paper trained their models on 200 of the subjects and then tested it on the remaining 50. Existing models using the same method achieved scores between 90-95% while the new models just slightly beat these with scores of 95.6% and 96% in the pseudo-real-time tests. This is a very simple test with a dataset from a larger number of people, and it has been shown that these machine learning algorithms are very accurate in this test and there is little progress to be made in accuracy.&lt;/p&gt;
&lt;h2&gt;Points of Interest&lt;/h2&gt;
&lt;p&gt;Machine learning algorithms with SVM models and CNN models have been done before, but this paper has proposed a new model that had improvements over previous models across the board. The researchers found that different people do have differences in their brain activity when reacting to the same stimuli. This is even more interesting when they found that the algorithm could become more accurate when it was learning and updating while it was acting as a BCI with a single individual. This is one aspect of the machine learning technology that could be very useful in creating effective BCIs. While the signature of brain activity is slightly different between people, the researchers found that the latency between input and brain activity spikes were very consistent between different people. This latency was also different when comparing different types of sensory inputs. This could prove a useful piece of information to develop algorithms like this in the future.&lt;/p&gt;
&lt;p&gt;The MEG data could scan the brain at 1000Hz, but the researchers found that downscaling the temporal resolution to 125Hz did not reduce the performance of the algorithms, while improving the computational requirements. Furthermore, the LF-CNN was made simpler for the purpose of being able to reverse engineer and observe what the model was using to make predictions. This effectively gave the researchers a heat-map of the brain that showed what areas reacted the most to a given stimuli. This allowed the researchers to compare the machine learnt model with established neuroscience knowledge of the brain, and the results showed very significant correlation.&lt;/p&gt;
&lt;div class="wp-block-spacer" style="height:100px;" aria-hidden="true"&gt;

&lt;/div&gt;

&lt;h2&gt;Reference&lt;/h2&gt;
&lt;p&gt;Subject Paper: "Adaptive neural network classifier for decoding MEG signals"&lt;br&gt;
https://www.sciencedirect.com/science/article/pii/S1053811919303544&lt;/p&gt;</content><category term="Post"></category><category term="BCI"></category><category term="CNN"></category><category term="Machine Learning"></category><category term="Neuroscience"></category></entry><entry><title>Using Type Systems for Taint Analysis for Android Apps</title><link href="https://RoshanStacker.github.io/type-based-taint-analysis.html" rel="alternate"></link><published>2020-04-28T04:15:00+10:00</published><updated>2020-04-28T04:15:00+10:00</updated><author><name>roshanstacker</name></author><id>tag:roshanstacker.github.io,2020-04-28:/type-based-taint-analysis.html</id><summary type="html">&lt;h2&gt;What is Taint Analysis?&lt;/h2&gt;
&lt;p&gt;Taint analysis for android apps is the process of detecting applications which collect users' sensitive information and leaks them to external sources, regardless of the the application developers did this maliciously or accidentally. The two methods for doing this analysis is dynamic and static, where dynamic …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;What is Taint Analysis?&lt;/h2&gt;
&lt;p&gt;Taint analysis for android apps is the process of detecting applications which collect users' sensitive information and leaks them to external sources, regardless of the the application developers did this maliciously or accidentally. The two methods for doing this analysis is dynamic and static, where dynamic is done by monitoring an application while it is being run. Due to this analysis being performed alongside the application, the application will run slower. Another major short coming of the dynamic approach is that it will only detect leaking of sensitive data (taint) if it is actually leaked during the runtime when the analysis takes place. Meaning that it will fail to detect taint in some applications. The alternative is static taint analysis which is what I will talk about here.&lt;/p&gt;
&lt;p&gt;Static taint analysis involves looking at the program code itself without running the program. There are many benefits over dynamic here, such as not having to run the app that may be malicious, having full access to the app's capabilities (without having to run the app and run all branches of the tree) and being able to run the app after without any slowdown. Static analysis is easy with android apps as the .apk file they are stored in can be de-compiled into java source code, and the source code can be analysed including libraries and classes.&lt;/p&gt;
&lt;p&gt;The authors Wei Huang, Yao Dong, Ana Milanova and Julian Dolby who have written the paper on this topic referenced below, have presented the systems, DFlow and DroidInfer. The authors have presented this system to demonstrate a method of performing static taint analysis, using a &lt;em&gt;type system&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Type Systems&lt;/h2&gt;
&lt;p&gt;A type system in programming is the idea that variables and pieces of data have a type, such as integer, floating point, string, etc. and depending on the type of the data, certain operations and conversions can or cannot take place. For example, it is possible to change an integer into a float, and to multiply a float by an integer, but trying to convert an integer to a string is not possible in a simple way using type conversion (it requires a more substantial algorithm). Type systems are often used to detect bugs in code during compilation where it can check if operations and conversions make sense. The system proposed by the authors of the paper use their system to analyse the source code of the programs in a similar fashion to a compiler.&lt;/p&gt;
&lt;h2&gt;Analysing Taint with a Type System&lt;/h2&gt;
&lt;p&gt;The technique proposed in the paper uses two types that are applied to variables in the source code; &lt;strong&gt;Safe&lt;/strong&gt; and &lt;strong&gt;Tainted&lt;/strong&gt; (some variables can have no type and be ignored). A safe variable is a variable that contains sensitive information. A variable becomes safe when it is assigned a value from a source or sensor that is considered sensitive, such as GPS location or device ID. If a variable takes a value from a safe variable, the variable also becomes safe. An example would be a variable that is storing the device ID and is set to type safe, then a second variable that is a URL string appends the device ID variable, the URL variable is then set to type safe due to appending a safe variable. The flow of assigning the safe type to the source code goes forwards through the code similar to the execution of the program.&lt;/p&gt;
&lt;p&gt;The tainted variable type is one that is eventually sent to an "untrusted sink". This could be a data log file or being sent over a HTTP web request. This means a tainted variable is a variable that gets sent to an untrusted place. When tainted variable takes a value from another variable, the variable becomes tainted as well. An example would be loading a URL string for a http request, which sets the URL string to be tainted. Before the request, the URL string was constructed using a combination of multiple strings and variables, all these variables become tainted too. The flow of assigning the tainted variable type goes backwards from the sink to the variable declaration, the opposite to the safe type.&lt;/p&gt;
&lt;p&gt;The rules of the type system state that a safe variable cannot be declared a tainted variable and vice versa. So when the type system is run over source code, a type error will occur when a safe variable and a tainted variable have a data flow, which represents data from a sensitive source in a safe variable, flowing into a tainted variable which eventually sends the data to an untrusted sink, hence marking the program as tainted. Therefore a type error in the type system means the program is tainted. This is how the system proposed in the paper works. The only input from the user to use the system is flagging the sensitive data sources and untrusted data sinks.&lt;/p&gt;
&lt;h2&gt;The Results&lt;/h2&gt;
&lt;p&gt;In the paper, the authors tested their taint analysis systems with other system that are already available. The results showed their new system to have a similar accuracy when it flagged apps as tainted, but had a significant reduction in the number of tainted data flows that were missed.&lt;/p&gt;
&lt;div class="wp-block-spacer" style="height:118px;" aria-hidden="true"&gt;

&lt;/div&gt;

&lt;h2&gt;Reference&lt;/h2&gt;
&lt;p&gt;"Scalable and precise taint analysis for Android", Wei Huang, Yao Dong, Ana Milanova and Julian Dolby https://dl.acm.org/doi/10.1145/2771783.2771803&lt;/p&gt;</content><category term="Post"></category><category term="Android"></category><category term="Taint Analysis"></category><category term="Type System"></category></entry></feed>